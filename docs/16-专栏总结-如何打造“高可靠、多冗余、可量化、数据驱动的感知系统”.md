
@[TOC](目录)


![在这里插入图片描述](https://img-blog.csdnimg.cn/80be89a6e1344b6e96981322d26b71e8.png)

1. 高可靠：对障碍物、红绿灯的识别精度有保证
2. 多冗余：各个模块相互支撑、非串行
3. 可量化：PRT、仿真场景测试、Profiling
4. 数据驱动（全流程闭环）


### 「超融合」感知方案

专注在Robobus市场的轻舟智航，也开始了L2城市NOA的布局。仔细看了下他们的技术方案，轻舟的多传感器时序穿插融合很有特点，官方称之为「超融合」感知方案。

多传感器的融合方案，目前行业主流的方式包括：前融合、中融合和后融合。

![在这里插入图片描述](https://img-blog.csdnimg.cn/54d24b2b56b34bf98203b5ad473948a9.png)



前融合属于数据级融合，基于多种传感器的原始数据，更早融合能够保留数据关联性，减少数据缺失。难点是：视觉数据和激光雷达的点云是异构数据，视觉是2D图像，激光雷达点云是3D空间，因此需要考虑空间标定和时间的同步，对算力有极高的要求。

后融合则是传感器各自对目标进行识别，通过深度学习理解后输出结果，在决策层进行融合，好处是硬件与软件解耦，算法部署更简单。缺点是在单独融合的过程中，可能会丢失细节信息，并且过于依赖模型和仿真训练。

所以行业目前普遍的做法，就是通过BEV的方式进行中融合。而轻舟智航采用的「超融合」方案，更像是在中融合基础上的进化。


![在这里插入图片描述](https://img-blog.csdnimg.cn/2d8798f1ab594ef7961685e5e4c16703.png)


与其他中融合方案的不同之处在于，轻舟提出了时序多模态特征融合的大模型OmniNet，通过一个神经网络即可实现视觉、激光雷达、毫米波雷达在BEV空间和图像空间上输出多任务结果。

![在这里插入图片描述](https://img-blog.csdnimg.cn/39126a54290a4c6da4315fa26daeb1b8.png)

通过前中融合阶段，优化对平台的算力消耗，给预测和规控提供更好的基础。
